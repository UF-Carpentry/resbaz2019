# Compute Day Details

Friday 13th September

Time		|Stream 1			|Stream 2a			|Stream 2b			|Stream 3
---			|---				|---				|---				|---	
09:30-11:00	|NCI and NCMAS		|GCP Hands on		|MS Azure Hands on	|Intro to Linux and HPC
11:30-12:30	|(cont'd)			|(cont'd)			|(cont'd)			|(cont'd)
13:15-14:15	|Pawsey				|AWS/Ronin Hands on	|					|Mathworks 1
14:15-15:15	|(cont'd)			|(cont'd)			|					|Mathworks 2
15:15-15:15	|UNSW Katana		|(cont'd)			|					|Mathworks 3


## NCI (Stream 1)

09:30-12:30

 - Introduction to NCI and Gadi, NCI's new high performance machine.
 - Introduction to the <a href="https://ncmas.nci.org.au/2020/">National Computational Merit Allocation Scheme (NCMAS)</a>.

## Pawsey (Stream 1)

13:15 - 15:00

*“Is your science causing your laptop to melt? Identifying when to scale your research.”*

How do you know when your dataset becomes “big data”? How do you know when your laptop can no longer do what you need it to do for your research? When is it best to use Cloud resources? When is it best to use super compute resources? When do I need both? 
 
The answers to these questions are project-dependent, and each project is different… but there are guidelines and best practices to help you decide.
 
During this workshop, we seek to answer these and associated questions. We use real stories from individuals who have had to navigate these same questions. Pawsey Supercomputing Centre staff will be on hand to facilitate discussion and provide insight, based on years of experience working with early, mid and late career researchers.

### UNSW Katana

15:00-16:15

An introduction to <a href="https://research.unsw.edu.au/katana">UNSW's Katana</a> (a service for UNSW researchers).

What do you do when your computing needs can no longer be met by your desktop or laptop? The obvious solution is to purchase a workstation or server, perhaps with some specialized hardware like GPUs. But this leads to the question of where it is going to be located and who is going to support it.

Katana is a modular computational cluster where the core infrastructure such as networking, storage and several shared nodes are already paid for. Research groups who wish to use the system more extensively than a base level provided to everyone at UNSW, or those who wish to purchase specialized hardware can buy one or more compute nodes and let ResTech do the rest. This co-investment model has allowed Katana to grow from an initial 5 compute nodes to the current size of over 100 nodes making it the primary on campus resource for research computing.

## Stream 2

Industry Tools - GCP, MS Azure, AWS/Ronin

Note that GCP and MS Azure run in parallel.

### Google Cloud Platform (GCP)

09:30-12:30

TBA

### MS Azure Hands on workshop

09:30-12:30

1. Introduce the fundamentals of Azure services and data movement.
2. Show how Azure tools can be used to provision high-performance computing services, including those relevant to Artificial Intelligence.
3. Demonstrate how Azure could be used to easily deploy parallel workloads at scale with minimal development.
4. Showcase how Azure is being leveraged by researchers to accelerate research output.
5. Discuss opportunities to leverage the Microsoft team for your computing needs.

### AWS/Ronin

13:15 - 16:15

TBA

## Stream 3

### Intro to Linux and HPC

09:30-12:30

A free hands-on tutorial for beginners to Linux and/or High Performance Computing.  No prior Linux or HPC knowledge or experience required!

Topics covered will include:

- How to connect to a HPC system using Secure Shell
- Using the BASH shell: commands, directories
- Transferring files to and from HPC systems
- Editing files using Nano or another text editor
- Simple scripting: creating shell script files, looping, variables
- Submitting and deleting jobs
- Checking on job status
- Discovering job queues and resources

You may wish to look through the <a href="https://www.zap.org.au/~john/links/intro-to-linux-and-hpc.pdf">course notes before attending</a>; this is entirely optional.  Additional verbal material will be presented during the tutorial.

### Mathworks

Three (1 hour) sessions, loosely connected in tools and approach, but sufficiently independent to permit selective attendance.

#### Managing and pre-processing messy data with MATLAB

13:15 - 14:15

This session presents a variety of new MATLAB® features for accessing, organizing, and analyzing data. A special focus on:

1. the MATLAB datastore framework for working with large collections of files and
2. MATLAB datatypes for organizing and pre-processing sensor data.

See how these tools enable technical teams to grow from ad-hoc data analysis to building centralized tools for organization-wide use, laying a foundation for delivering production apps and analytics.
 
#### Deep Learning and Reinforcement Learning Workflows in AI

14:15 - 15:15

AI techniques are underpinning a dramatic change in research and analysis. Two new workflows, Deep Learning and Reinforcement Learning, are transforming industries and improving applications such as diagnosing medical conditions, driving autonomous vehicles, and controlling robots.. This session will cover:

- Machine Learning with code and APPS. Extending to automatic conversion of the Machine Learning designs to  (C/C++)
- Deep Learning via CNNs with code and APPS, extending to automatic conversion to CUDA for high speed execution on GPU's
- Importing Deep Learning models from other languages/networks via ONNX  into MATLAB.
- Reinforcement learning in MATLAB
- Application examples  including: Cancer diagnosis & Semantic segmentation for computer vision systems on autonomous vehicles
 
#### Speeding up MATLAB Applications

15:15 - 16:15

Learn strategies and techniques for speeding up your MATLAB applications. Included are tips on how to optimize the performance of the MATLAB code itself and how to use the MATLAB family of products to take advantage of advances in hardware, such as multicore desktops, computer clusters, and public clouds.
